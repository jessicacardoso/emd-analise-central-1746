{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clusterização dos chamados a Central 1746\n",
    "\n",
    "Nesse notebook, prentedemos identificar grupos de chamados a Central 1746 que possam ser tratados de forma semelhante. Para isso, utilizamos técnicas de clusterização, que são técnicas de aprendizado não supervisionado que buscam agrupar dados semelhantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_gbq\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import matplotlib.gridspec as gridspec\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecionamos algumas colunas com base na análise exploratória feita no notebook de previsão de chamados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\n",
    "    \"../data/chamado_1746.parquet\",\n",
    "    columns=[\n",
    "        \"id_chamado\",\n",
    "        \"id_bairro\",\n",
    "        \"data_inicio\",\n",
    "        \"data_fim\",\n",
    "        \"tipo\",\n",
    "        \"subtipo\",\n",
    "        \"status\",\n",
    "        \"nome_unidade_organizacional\",\n",
    "        \"unidade_organizacional_ouvidoria\",\n",
    "        \"data_alvo_finalizacao\",\n",
    "        \"data_alvo_diagnostico\",\n",
    "        \"prazo_unidade\",\n",
    "        \"prazo_tipo\",\n",
    "        \"dentro_prazo\",\n",
    "        \"situacao\",\n",
    "        \"latitude\",\n",
    "        \"longitude\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "df = df.set_index(\"id_chamado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformação dos dados\n",
    "\n",
    "A partir das variáveis de datas, foram extraídas as seguintes variáveis:\n",
    "- tempo decorrido\n",
    "- urgente\n",
    "- tempo estimado finalizar\n",
    "- tempo estimado diagnosticar \n",
    "- dia da semana\n",
    "- dia do mês\n",
    "- estações do ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tempo_decorrido\"] = (df[\"data_fim\"] - df[\"data_inicio\"]).dt.total_seconds() / 3600\n",
    "\n",
    "df[\"urgente\"] = (\n",
    "    df[\"data_alvo_finalizacao\"] - df[\"data_inicio\"]\n",
    ").dt.total_seconds() / 3600 <= 24\n",
    "\n",
    "df[\"tempo_estimado_finalizar\"] = (\n",
    "    df[\"data_alvo_finalizacao\"] - df[\"data_inicio\"]\n",
    ").dt.total_seconds() / 3600\n",
    "\n",
    "df[\"tempo_estimado_diagnosticar\"] = (\n",
    "    df[\"data_alvo_diagnostico\"] - df[\"data_inicio\"]\n",
    ").dt.total_seconds() / 3600\n",
    "\n",
    "\n",
    "df.drop(\n",
    "    columns=[\"data_alvo_finalizacao\", \"data_alvo_diagnostico\", \"data_fim\"],\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"dia_semana\"] = pd.Categorical(\n",
    "    df[\"data_inicio\"]\n",
    "    .dt.day_name()\n",
    "    .replace(\n",
    "        {\n",
    "            \"Monday\": \"Segunda\",\n",
    "            \"Tuesday\": \"Terça\",\n",
    "            \"Wednesday\": \"Quarta\",\n",
    "            \"Thursday\": \"Quinta\",\n",
    "            \"Friday\": \"Sexta\",\n",
    "            \"Saturday\": \"Sábado\",\n",
    "            \"Sunday\": \"Domingo\",\n",
    "        }\n",
    "    ),\n",
    "    categories=[\n",
    "        \"Segunda\",\n",
    "        \"Terça\",\n",
    "        \"Quarta\",\n",
    "        \"Quinta\",\n",
    "        \"Sexta\",\n",
    "        \"Sábado\",\n",
    "        \"Domingo\",\n",
    "    ],\n",
    "    ordered=True,\n",
    ")\n",
    "df[\"mes\"] = pd.Categorical(\n",
    "    df[\"data_inicio\"]\n",
    "    .dt.month_name()\n",
    "    .replace(\n",
    "        {\n",
    "            \"January\": \"Janeiro\",\n",
    "            \"February\": \"Fevereiro\",\n",
    "            \"March\": \"Março\",\n",
    "            \"April\": \"Abril\",\n",
    "            \"May\": \"Maio\",\n",
    "            \"June\": \"Junho\",\n",
    "            \"July\": \"Julho\",\n",
    "            \"August\": \"Agosto\",\n",
    "            \"September\": \"Setembro\",\n",
    "            \"October\": \"Outubro\",\n",
    "            \"November\": \"Novembro\",\n",
    "            \"December\": \"Dezembro\",\n",
    "        }\n",
    "    ),\n",
    "    categories=[\n",
    "        \"Janeiro\",\n",
    "        \"Fevereiro\",\n",
    "        \"Março\",\n",
    "        \"Abril\",\n",
    "        \"Maio\",\n",
    "        \"Junho\",\n",
    "        \"Julho\",\n",
    "        \"Agosto\",\n",
    "        \"Setembro\",\n",
    "        \"Outubro\",\n",
    "        \"Novembro\",\n",
    "        \"Dezembro\",\n",
    "    ],\n",
    "    ordered=True,\n",
    ")\n",
    "df[\"dia_mes\"] = df[\"data_inicio\"].dt.day\n",
    "\n",
    "# Primavera:20 de março a 21 de junho\n",
    "# Verão:21 de junho a 23 de setembro\n",
    "# Outono:23 de setembro a 21 de dezembro\n",
    "# Inverno:21 de dezembro a 20 de março\n",
    "# Os anos de 2022 e 2023 não são bissextos, então fevereiro tem 28 dias\n",
    "\n",
    "# inverno primeira parte\n",
    "df.loc[df[\"data_inicio\"].dt.dayofyear.between(0, 79), \"estacao\"] = \"Inverno\"\n",
    "# demais estações\n",
    "df.loc[df[\"data_inicio\"].dt.dayofyear.between(79, 172), \"estacao\"] = \"Primavera\"\n",
    "df.loc[df[\"data_inicio\"].dt.dayofyear.between(172, 266), \"estacao\"] = \"Verão\"\n",
    "df.loc[df[\"data_inicio\"].dt.dayofyear.between(266, 355), \"estacao\"] = \"Outono\"\n",
    "# inverno segunda parte\n",
    "df.loc[df[\"data_inicio\"].dt.dayofyear.between(355, 366), \"estacao\"] = \"Inverno\"\n",
    "\n",
    "df[\"estacao\"] = pd.Categorical(\n",
    "    df[\"estacao\"],\n",
    "    categories=[\"Primavera\", \"Verão\", \"Outono\", \"Inverno\"],\n",
    "    ordered=True,\n",
    ")\n",
    "\n",
    "df.drop(columns=[\"data_inicio\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também realizamos a padronização de algumas variáveis, transformando algumas colunas no tipo categórico. Sendo elas:\n",
    "\n",
    "- prazo_unidade\n",
    "- prazo_tipo\n",
    "- dentro_prazo\n",
    "- status\n",
    "- unidade_organizacional_ouvidoria\n",
    "- id_bairro\n",
    "- situacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"prazo_unidade\"] = df[\"prazo_unidade\"].replace({\"D\": \"dias\", \"H\": \"horas\"})\n",
    "df[\"prazo_unidade\"] = pd.Categorical(\n",
    "    df[\"prazo_unidade\"], categories=[\"dias\", \"horas\"], ordered=True\n",
    ")\n",
    "\n",
    "df[\"prazo_tipo\"] = df[\"prazo_tipo\"].replace({\"D\": \"Diagnóstico\", \"F\": \"Finalização\"})\n",
    "df[\"prazo_tipo\"] = pd.Categorical(\n",
    "    df[\"prazo_tipo\"], categories=[\"Diagnóstico\", \"Finalização\"], ordered=True\n",
    ")\n",
    "\n",
    "df[\"dentro_prazo\"] = pd.Categorical(\n",
    "    df[\"dentro_prazo\"], categories=[\"Fora do prazo\", \"No prazo\"], ordered=True\n",
    ")\n",
    "\n",
    "df[\"status\"] = pd.Categorical(\n",
    "    df[\"status\"], categories=df[\"status\"].value_counts().index\n",
    ")\n",
    "\n",
    "df[\"unidade_organizacional_ouvidoria\"] = pd.Categorical(\n",
    "    df[\"unidade_organizacional_ouvidoria\"],\n",
    "    categories=df[\"unidade_organizacional_ouvidoria\"].value_counts().index,\n",
    ")\n",
    "\n",
    "df[\"id_bairro\"] = pd.Categorical(\n",
    "    df[\"id_bairro\"], categories=df[\"id_bairro\"].value_counts().index\n",
    ")\n",
    "df[\"situacao\"] = pd.Categorical(\n",
    "    df[\"situacao\"], categories=[\"Não Encerrado\", \"Encerrado\"], ordered=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento dos dados \n",
    "\n",
    "As colunas tipo, subtipo e nome da unidade organizacional tiveram seus embeddings extraídos a partir de um modelo pré-treinado. Em seguida, todas as variáveis foram padronizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"distiluse-base-multilingual-cased-v2\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "\n",
    "def encode_text(texts: pd.Series, model: SentenceTransformer) -> np.ndarray:\n",
    "    unique_text = texts.unique()\n",
    "    encoded = model.encode(unique_text)\n",
    "    return encoded\n",
    "\n",
    "\n",
    "def pca_encode_text(texts, n_components=50):\n",
    "    return PCA(n_components=n_components).fit_transform(texts)\n",
    "\n",
    "\n",
    "preprocessor = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", imputer),\n",
    "        (\"scaler\", scaler),\n",
    "    ]\n",
    ").set_output(transform=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cols = [\"tipo\", \"subtipo\", \"nome_unidade_organizacional\"]\n",
    "text_dimensions = [25, 50, 100]\n",
    "encoded_cols = []\n",
    "\n",
    "for col, n_componentes in zip(text_cols, text_dimensions):\n",
    "    encoded = encode_text(df[col], model)\n",
    "    pca_encoded = pca_encode_text(encoded, n_componentes)\n",
    "    mapping = dict(zip(df[col].unique(), pca_encoded))\n",
    "    mapped = df[col].map(mapping)\n",
    "    encoded_cols.append(\n",
    "        pd.DataFrame(np.array(mapped.tolist()), index=df.index).add_prefix(f\"{col}_\")\n",
    "    )\n",
    "\n",
    "df_encoded = pd.concat(encoded_cols, axis=1)\n",
    "dataset = pd.concat([df, df_encoded], axis=1)\n",
    "dataset.drop(columns=text_cols, inplace=True, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "categorical_cols = dataset.select_dtypes(include=[\"category\"]).columns.tolist()\n",
    "dataset[categorical_cols] = ordinal_encoder.fit_transform(dataset[categorical_cols])\n",
    "dataset[categorical_cols] = dataset[categorical_cols]\n",
    "dataset = preprocessor.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento modelo\n",
    "\n",
    "Foi utilizado o algoritmo KMeans para realizar a clusterização dos chamados. O número de clusters foi escolhido para uma rápida análise sobre os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "kmeans.fit(dataset)\n",
    "clusters = kmeans.predict(dataset)\n",
    "df[\"cluster\"] = clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisar clusters\n",
    "\n",
    "Após a clusterização, foi feita uma análise dos clusters gerados, com o objetivo de identificar padrões e comportamentos dos chamados. Para uma visualização mais clara, foi utilizado o algoritmo PCA para redução de dimensionalidade dos dados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_embedded = PCA(n_components=2, random_state=0).fit_transform(dataset)\n",
    "\n",
    "plt.scatter(dataset_embedded[:, 0], dataset_embedded[:, 1], c=kmeans.labels_)\n",
    "plt.xlabel(\"First principal component\")\n",
    "plt.ylabel(\"Second principal component\")\n",
    "plt.title(\"K-means clustering with 2 dimensions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que os clusters 1 e 2 possuem menor tempo na média para finalizar o atendimento, enquanto o cluster 3 possui a maior média."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_stats = (\n",
    "    df.reset_index()\n",
    "    .groupby(\"cluster\")\n",
    "    .agg(\n",
    "        {\n",
    "            \"tempo_decorrido\": [\"min\", \"max\", \"mean\"],\n",
    "            \"tempo_estimado_finalizar\": [\"min\", \"max\", \"mean\"],\n",
    "            \"tempo_estimado_diagnosticar\": [\"min\", \"max\", \"mean\"],\n",
    "            \"id_chamado\": \"count\",\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "cluster_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 5, figsize=(20, 5))\n",
    "fig.suptitle(\"Distribuição de prazo por cluster\")\n",
    "for i in range(5):\n",
    "    ax = axes[i]\n",
    "    sns.histplot(\n",
    "        df[df[\"cluster\"] == i][\"dentro_prazo\"],\n",
    "        kde=True,\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set_title(f\"Cluster {i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo temos as imagens com distribuição dos status dos chamados em cada cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 12))\n",
    "specs = gridspec.GridSpec(nrows=2, ncols=3, figure=fig)\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    ax = fig.add_subplot(specs[i // 3, i % 3])\n",
    "    sns.histplot(\n",
    "        df[df[\"cluster\"] == i][\"status\"],\n",
    "        kde=True,\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set_title(f\"Cluster {i}\")\n",
    "    ax.tick_params(axis=\"x\", rotation=90)\n",
    "    plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, destacamos os subtipos mais comuns em cada cluster, vemos que:\n",
    "\n",
    "- Cluster 1: Os subtipos mais comuns são relacionados a lâmpadas\n",
    "- Cluster 2: Tem mais chamados relacionados a ônibus\n",
    "- Cluster 3: Esse cluster agrupou mais chamados relacionados a fiscalização\n",
    "- Cluster 4: Tem chamados relacionados a obstrução via pública como bueiros, animais sivelstres.\n",
    "- Cluster 5: Tem chamados relacionados a limpeza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 18))\n",
    "specs = gridspec.GridSpec(nrows=2, ncols=3, figure=fig)\n",
    "\n",
    "for i in range(5):\n",
    "    ax = fig.add_subplot(specs[i // 3, i % 3])\n",
    "    df[clusters == i][\"subtipo\"].value_counts().head(10).plot(kind=\"bar\", ax=ax)\n",
    "    ax.set_title(f\"Cluster {i}\")\n",
    "    ax.tick_params(axis=\"x\", rotation=90)\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise bairros\n",
    "\n",
    "Por fim, nessa seção mostramos os plots para cada bairro de acordo com o cluster selecionado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_choropleth(calls: pd.DataFrame, neighborhoods: pd.DataFrame) -> go.Figure:\n",
    "    \"\"\"\n",
    "    Cria um mapa de coroplético com base nos chamados por bairro.\n",
    "\n",
    "    Args:\n",
    "        calls (pd.DataFrame): O dataframe contendo os chamados.\n",
    "        neighborhoods (pd.DataFrame): O dataframe contendo os bairros.\n",
    "\n",
    "    Returns:\n",
    "        go.Figure: O objeto figura do Plotly contendo o mapa de coroplético.\n",
    "    \"\"\"\n",
    "    # Agrupa os chamados por bairro\n",
    "    neighboards_calls = (\n",
    "        calls.merge(neighborhoods, how=\"right\", on=\"id_bairro\")\n",
    "        .groupby(\"id_bairro\")\n",
    "        .agg(\n",
    "            {\n",
    "                \"id_bairro\": \"count\",\n",
    "                # \"nome\": \"first\",\n",
    "                \"geometry\": \"first\",\n",
    "            }\n",
    "        )\n",
    "        .rename(columns={\"id_bairro\": \"chamados\"})\n",
    "        .sort_values(\"chamados\", ascending=False)\n",
    "    )\n",
    "\n",
    "    # Cria um GeoDataFrame a partir do resultado\n",
    "    neighboards_calls = gpd.GeoDataFrame(\n",
    "        neighboards_calls,\n",
    "        geometry=gpd.GeoSeries.from_wkt(neighboards_calls[\"geometry\"]),\n",
    "        crs=\"EPSG:4326\",\n",
    "    )\n",
    "\n",
    "    # Cria o mapa de coroplético\n",
    "    fig = px.choropleth_mapbox(\n",
    "        neighboards_calls,\n",
    "        geojson=neighboards_calls[\"geometry\"],\n",
    "        locations=neighboards_calls.index,\n",
    "        color=\"chamados\",\n",
    "        color_continuous_scale=\"Blues\",\n",
    "        range_color=(0, neighboards_calls[\"chamados\"].max()),\n",
    "        mapbox_style=\"carto-positron\",\n",
    "        zoom=8.5,\n",
    "        center={\"lat\": -22.914469232838503, \"lon\": -43.4461895474592},\n",
    "        opacity=0.6,\n",
    "        # hover_data={\"nome\": True,  \"chamados\": True},\n",
    "        width=400,\n",
    "        height=350,\n",
    "    )\n",
    "\n",
    "    # Configurações adicionais para o layout do gráfico\n",
    "    fig.update_layout(\n",
    "        coloraxis_showscale=False,\n",
    "        margin={\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0},\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bairro = pd.read_parquet(\n",
    "    \"../data/bairro.parquet\", columns=[\"id_bairro\", \"nome\", \"geometry\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_chamado_1746 = df.merge(bairro, how=\"left\", on=\"id_bairro\")\n",
    "raw_chamado_1746[\"cluster\"] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top-5 subtipos mais comuns:\")\n",
    "print(df[df[\"cluster\"] == 0][\"subtipo\"].value_counts().head(5).index)\n",
    "\n",
    "fig = make_choropleth(df[df[\"cluster\"] == 0], bairro)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top-5 subtipos mais comuns:\")\n",
    "print(df[df[\"cluster\"] == 1][\"subtipo\"].value_counts().head(5).index)\n",
    "fig = make_choropleth(df[df[\"cluster\"] == 1], bairro)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top-5 subtipos mais comuns:\")\n",
    "print(df[df[\"cluster\"] == 2][\"subtipo\"].value_counts().head(5).index)\n",
    "fig = make_choropleth(df[df[\"cluster\"] == 2], bairro)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top-5 subtipos mais comuns:\")\n",
    "print(df[df[\"cluster\"] == 3][\"subtipo\"].value_counts().head(5).index)\n",
    "fig = make_choropleth(df[df[\"cluster\"] == 3], bairro)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top-5 subtipos mais comuns:\")\n",
    "print(df[df[\"cluster\"] == 4][\"subtipo\"].value_counts().head(5).index)\n",
    "fig = make_choropleth(df[df[\"cluster\"] == 4], bairro)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma análise adicional mais detalhada é necessária para entender melhor os clusters e identificar padrões e comportamentos dos chamados. Mas, com base na análise feita, identificamos que há grupos que podem ser verificados de forma semelhante."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
